{
  "name": "001_sr_template"
  , "use_tb_logger": true
  , "model":"sr"
  , "scale": 4
  , "gpu_ids": [0]
  , "use_amp": true
  , "use_swa": false
  , "use_cem": false
  , "use_atg": false

  // Dataset options:
  , "datasets": {
    "train": {
      "name": "DIV2K"
      , "mode": "aligned"
      , "dataroot_HR": [
            "../datasets/train/hr1",
            "../datasets/train/hr2",
            "../datasets/train/hr3"
            ] // high resolution / ground truth images
      , "dataroot_LR": [
            "../datasets/train/lr1",
            "../datasets/train/lr2"
            // "../datasets/train/lr3"
            ] // low resolution images
      , "subset_file": null
      , "use_shuffle": true
      , "znorm": false
      , "n_workers": 4
      , "batch_size": 8
      , "virtual_batch_size": 8
      , "preprocess": "crop"
      , "crop_size": 128
      , "image_channels": 3
      
      // Color space conversion
      // , "color": "y"
      // , "color_LR": "y"
      // , "color_HR": "y"
      
      // Rotations augmentations:
      , "use_flip": true
      , "use_rot": true
      , "use_hrrot": false
      
      // Presets and on the fly (OTF) augmentations
      // , "augs_strategy": "combo"
      // , "aug_downscale": 0.2
      // , "resize_strat": "pre"
      
      // , "dataroot_kernels": "../training/kernels/results/"
      // , "noise_data": "../noise_patches/normal/"
      // , "pre_crop": true
      // , "hr_downscale": true
      // , "hr_downscale_amt": [2, 1.75, 1.5, 1]
      // , "shape_change": "reshape_lr"
    }
    , "val": {
      "name": "val_set14_part"
      , "mode": "aligned"
      , "dataroot_B": "../datasets/val/hr"
      , "dataroot_A": "../datasets/val/lr"
      
      , "znorm": false
      
      // Color space conversion:
      // , "color": "y"
      // , "color_LR": "y"
      // , "color_HR": "y"
      
      , "lr_downscale": false
      , "lr_downscale_types": ["linear", "cubic"]
    }
  }

  , "path": {
    "root": "../"
    , "pretrain_model_G": "../experiments/pretrained_models/RRDB_PSNR_x4.pth"
    // , "pretrain_model_D": "../experiments/pretrained_models/patchgan.pth"
    // , "pretrain_model_Loc": "../experiments/pretrained_models/locnet.pth"
    // , "resume_state": "../experiments/debug_002_RRDB_ESRGAN_x4_DIV2K/training_state/16.state"
  }

  // Generator options:
  , "network_G": "esrgan"

  // Discriminator options:
  , "network_D": "discriminator_vgg"

  , "train": {
    // Optimizer options:
    "optim_G": "adam"
    , "optim_D": "adam"

    // Schedulers options:
    , "lr_scheme": "MultiStepLR"
    , "lr_steps_rel": [0.1, 0.2, 0.4, 0.6]
    , "lr_gamma": 0.5

    // For SWA scheduler
    , "swa_start_iter_rel": 0.75
    , "swa_lr": 1e-4
    , "swa_anneal_epochs": 10
    , "swa_anneal_strategy": "cos"

    // For AdaTarget
    , "atg_start_iter_rel": 0.83
    
    // Losses:
    , "pixel_criterion": "l1" // pixel (content) loss
    , "pixel_weight": 1e-2
    , "feature_criterion": "l1" // feature loss (VGG feature network)
    , "feature_weight": 1
    // , "cx_type": "contextual" // contextual loss
    // , "cx_weight": 0.5
    // , "cx_vgg_layers": {"conv_3_2": 1.0, "conv_4_2": 1.0}
    // , "hfen_criterion": "l1" // hfen
    // , "hfen_weight": 1e-6
    // , "grad_type": "grad-4d-l1" // image gradient loss
    // , "grad_weight": 4e-3
    // , "tv_type": "normal" // total variation
    // , "tv_weight": 1e-5
    // , "tv_norm": 1
    // , "ssim_type": "ssim" // structural similarity
	  // , "ssim_weight": 1
    // , "lpips_weight": 1 // perceptual loss
    // , "lpips_type": "net-lin"
    // , "lpips_net": "squeeze"
    
    // Experimental losses
    // , "spl_type": "spl" // spatial profile loss
    // , "spl_weight": 1e-1
    // , "of_type": "overflow" // overflow loss
    // , "of_weight": 2e-1
    // , "range_weight": 1 // range loss
    // , "fft_type": "fft" // FFT loss
    // , "fft_weight": 1e-1
    // , "color_criterion": "color-l1cosinesim" // color consistency loss
    // , "color_weight": 1
    // , "avg_criterion": "avg-l1" // averaging downscale loss
    // , "avg_weight": 5
    // , "ms_criterion": "multiscale-l1" // multi-scale pixel loss
    // , "ms_weight": 1e-2
    // , "fdpl_type": "fdpl" // frequency domain-based perceptual loss
    // , "fdpl_weight": 1e-3

    // Adversarial loss:
    , "gan_type": "vanilla"
    , "gan_weight": 5e-3
    // , "freeze_loc": 4
    // for wgan-gp
    // , "D_update_ratio": 1
    // , "D_init_iters": 0
    // , "gp_weight": 10
    // Feature matching (if using the discriminator_vgg_128_fea or discriminator_vgg_fea):
    // , "gan_featmaps": true
    // , "dis_feature_criterion": "cb" // discriminator feature loss
    // , "dis_feature_weight": 1e-2

    // For PPON:
    // , "p1_losses": ["pix"]
    // , "p2_losses": ["pix-multiscale", "ms-ssim"]
    // , "p3_losses": ["fea"]
    // , "ppon_stages": [1000, 2000]

    // Differentiable Augmentation for Data-Efficient GAN Training
    // , "diffaug": true
    // , "dapolicy": "color,transl_zoom,flip,rotate,cutout"

    // Batch (Mixup) augmentations
    // , "mixup": true // true | false
    // , "mixopts": ["blend", "rgb", "mixup", "cutmix", "cutmixup"] //, "cutout", "cutblur"]
    // , "mixprob": [1.0, 1.0, 1.0, 1.0, 1.0] //, 1.0, 1.0]
    // , "mixalpha": [0.6, 1.0, 1.2, 0.7, 0.7] //, 0.001, 0.7]
    // , "aux_mixprob": 1.0
    // , "aux_mixalpha": 1.2
    // //, "mix_p": 1.2

    // Frequency Separator
    // , "fs": true
    // , "lpf_type": "average"
    // , "hpf_type": "average"

    // Other training options:
    , "manual_seed": 0
    , "niter": 5e5
    // , "warmup_iter": -1
    , "val_freq": 5e3
    // , "overwrite_val_imgs": true
    // , "val_comparison": true
    , "metrics": "psnr,ssim,lpips"
    , "grad_clip": "norm"
    , "grad_clip_value": 0.1 // "auto"
  }

  , "logger": {
    "print_freq": 200
    , "save_checkpoint_freq": 5e3
    , "overwrite_chkp": false
  }
}