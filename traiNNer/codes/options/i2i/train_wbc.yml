name: 001_wbc_template
use_tb_logger: true
model: wbc
scale: 1
gpu_ids: [0]
use_amp: true
use_swa: false
pool_size: 1

# Dataset options:
datasets:
  train:
    name: wbc
    mode: concat_unaligned
    sampler_weights: [4, 1]
    outputs: AB
    dataroot_B: [
      "../datasets/wbcdataset/scenery_cartoon",
      "../datasets/wbcdataset/face_cartoon"
      ]
    dataroot_A: [
      "../datasets/wbcdataset/scenery_photo",
      "../datasets/wbcdataset/face_photo"
      ]
    use_shuffle: true
    znorm: true
    n_workers: 2
    batch_size: 16
    virtual_batch_size: 16
    preprocess: 'crop'
    load_size: 256
    crop_size: 256
    input_nc: 3 # number of channels to load images in
    output_nc: 3
    image_channels: 3

    # Rotations augmentations:
    use_flip: true
    # use_rot: true
    # use_hrrot: false

path:
    root: '../'
    pretrain_model_G: '../experiments/pretrained_models/wbc.pth'
    # pretrain_model_D_T: "../experiments/pretrained_models/latest_D_T.pth"
    # pretrain_model_D_S: "../experiments/pretrained_models/latest_D_S.pth"
    # resume_state: '../experiments/001_wbc_template/training_state/latest.state'

# Generator options:
network_G:
    strict: false
    which_model_G: wbcunet

# Discriminator options:
network_D:
    strict: true
    which_model_D: patchgan
    spectral_norm: true
    nf: 32

train:
    # Optimizer options:
    optim_G: adam
    lr_G: 2e-4
    weight_decay_G: 0
    beta1_G: 0.5  # momentum term
    optim_D: adam
    lr_D: 2e-4
    weight_decay_D: 0
    beta1_D: 0.5  # momentum term

    # Schedulers options:
    lr_scheme: Linear
    fixed_niter: 5e4 # number of iterations with the initial learning rate
    niter_decay: 0 # number of iterations to linearly decay learning rate to zero (=niter-fixed_niter)
    
    # For SWA scheduler
    # swa_start_iter_rel: 0.75
    # swa_lr: 1e-4
    # swa_anneal_epochs: 10
    # swa_anneal_strategy: "cos"
    
    # Losses:
    # lambda_identity: 0.1
    # pixel_criterion: l1  # pixel (content) loss
    # pixel_weight: 1e-1
    feature_criterion: l1
    feature_weight: 0.002
    style_weight: 0.0
    perceptual_opt:
      perceptual_layers: {"conv4_4": 1.0}
      style_layers: {}
      rotations: false
      flips: false
      feature_network: "vgg19"
      remove_pooling: false
      use_input_norm: true
      requires_grad: false
      change_padding: false
      pretrained_path: null
    # cx_weight: 0.000001
    # cx_type: contextual
    # cx_vgg_layers: {conv_3_2: 1} # {conv_3_2: 1, conv_4_2: 1}
    # hfen_criterion: l1  # hfen
    # hfen_weight: 1e-6
    # grad_type: grad-4d-l1  # image gradient loss
    # grad_weight: 4e-1
    tv_type: normal  # total variation
    tv_weight: 0.045
    tv_norm: 2
    # ssim_type: ssim  # structural similarity
    # ssim_weight: 1
    # lpips_weight: 1 # perceptual loss
    # lpips_type: net-lin
    # lpips_net: squeeze
    
    # Experimental losses
    # spl_type: spl  # spatial profile loss
    # spl_weight: 0.1
    # of_type: overflow  # overflow loss
    # of_weight: 0.2
    # range_weight: 1  # range loss
    # fft_type: fft  # FFT loss
    # fft_weight: 0.1
    # color_criterion: color-l1cosinesim  # color consistency loss
    # color_weight: 1
    # avg_criterion: avg-l1  # averaging downscale loss
    # avg_weight: 5
    # ms_criterion: multiscale-l1  # multi-scale pixel loss
    # ms_weight: 1e-2
    # fdpl_type: fdpl  # frequency domain-based perceptual loss
    # fdpl_weight: 1e-3
    
    # Adversarial loss:
    gan_type: lsgan  # vanilla
    gan_weight: 0.02
    gan_opt:
      form: standard # standard | relativistic
      # conditional: false # true | false
    # freeze_loc: 4
    # For wgan-gp:
    # D_update_ratio: 1
    # D_init_iters: 0
    # gp_weight: 10
    # Feature matching (if using the discriminator_vgg_128_fea or discriminator_vgg_fea):
    # gan_featmaps: true
    # dis_feature_criterion: cb  # discriminator feature loss
    # dis_feature_weight: 0.01
    
    # Differentiable Augmentation for Data-Efficient GAN Training
    # diffaug: true
    # dapolicy: 'color,transl_zoom,flip,rotate,cutout'
    
    # Batch (Mixup) augmentations
    # mixup: true
    # mixopts: [blend, rgb, mixup, cutmix, cutmixup] # , "cutout", "cutblur"]
    # mixprob: [1.0, 1.0, 1.0, 1.0, 1.0] #, 1.0, 1.0]
    # mixalpha: [0.6, 1.0, 1.2, 0.7, 0.7] #, 0.001, 0.7]
    # aux_mixprob: 1.0
    # aux_mixalpha: 1.2
    ## mix_p: 1.2
    
    # Frequency Separator
    # fs: true
    # lpf_type: average
    # hpf_type: average

    # representation losses
    # surf_losses: []
    # text_losses: []
    struct_losses: [fea]
    cont_losses: [fea]
    reg_losses: [tv] # [tv, contextual]
    # idt_losses: [pix]

    # representation scales
    surface_scale: 0.2
    texture_scale: 1.0
    struct_scale: 1.0
    content_scale: 1.0
    reg_scale: 1.0

    # Other training options:
    manual_seed: 0
    niter: 5e4
    # warmup_iter: -1  # -1 for no warm up
    display_freq: 5e3
    # overwrite_val_imgs: true

logger:
    print_freq: 200
    save_checkpoint_freq: 5e3
    overwrite_chkp: false
